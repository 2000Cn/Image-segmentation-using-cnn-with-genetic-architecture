{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'dataset/train/'\n",
    "val_path = 'dataset/val/'\n",
    "test_path = 'dataset/test/'\n",
    "\n",
    "def load_images(folder_path):\n",
    "    image_folder = folder_path + 'images/'\n",
    "    mask_folder = folder_path + 'masks/'\n",
    "    images = []\n",
    "    masks = []\n",
    "    for filename in os.listdir(image_folder):\n",
    "        img = Image.open(os.path.join(image_folder, filename))\n",
    "        mask = Image.open(os.path.join(mask_folder, filename.replace('.tif', '.png')))\n",
    "        images.append(np.array(img))\n",
    "        masks.append(np.array(mask))\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "train_images, train_masks = load_images(train_path)\n",
    "val_images, val_masks = load_images(val_path)\n",
    "test_images, test_masks = load_images(test_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_dict = pd.read_csv('dataset/class_dict.csv')\n",
    "label_dict = {}\n",
    "\n",
    "for index, row in class_dict.iterrows():\n",
    "    label_dict[(row['r'], row['g'], row['b'])] = row['name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def masks_to_labels(masks, label_dict):\n",
    "    label_map = {label: i for i, label in enumerate(label_dict.keys())}\n",
    "    labels = []\n",
    "    for mask in masks:\n",
    "        mask = mask.astype('uint32')\n",
    "        label = np.zeros((mask.shape[0], mask.shape[1]))\n",
    "        for i in range(mask.shape[0]):\n",
    "            for j in range(mask.shape[1]):\n",
    "                label[i,j] = label_map.get(tuple(mask[i,j,:]), len(label_dict)-1)\n",
    "        labels.append(label)\n",
    "    return np.array(labels)\n",
    "\n",
    "\n",
    "train_labels = masks_to_labels(train_masks, label_dict)\n",
    "val_labels = masks_to_labels(val_masks, label_dict)\n",
    "test_labels = masks_to_labels(test_masks, label_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 22s 535ms/step - loss: 2875.4812 - accuracy: 0.0102 - val_loss: 1978.0280 - val_accuracy: 0.0072\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 16s 488ms/step - loss: 2872.4998 - accuracy: 0.0105 - val_loss: 1977.9896 - val_accuracy: 0.0090\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 17s 528ms/step - loss: 2872.5000 - accuracy: 0.0084 - val_loss: 1977.9645 - val_accuracy: 0.0087\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 16s 497ms/step - loss: 2872.4993 - accuracy: 0.0083 - val_loss: 1977.9645 - val_accuracy: 0.0086\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 16s 495ms/step - loss: 2872.4993 - accuracy: 0.0164 - val_loss: 1977.9645 - val_accuracy: 0.0145\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 16s 502ms/step - loss: 2872.4993 - accuracy: 0.0137 - val_loss: 1977.9645 - val_accuracy: 0.0084\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 16s 508ms/step - loss: 2872.4993 - accuracy: 0.0083 - val_loss: 1977.9645 - val_accuracy: 0.0084\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 16s 489ms/step - loss: 2872.4993 - accuracy: 0.0083 - val_loss: 1977.9647 - val_accuracy: 0.0084\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 15s 482ms/step - loss: 2872.4993 - accuracy: 0.0059 - val_loss: 1977.9647 - val_accuracy: 0.0021\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 16s 492ms/step - loss: 2872.4993 - accuracy: 0.0013 - val_loss: 1977.9647 - val_accuracy: 0.0022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a258592230>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Reshape\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same', input_shape=(120,120,3)))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(120*120, activation='softmax'))\n",
    "model.add(Reshape((120,120)))\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(train_images, train_labels, batch_size=32, epochs=10, validation_data=(val_images, val_labels))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from deap import base, creator, tools, algorithms\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Conv2DTranspose\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "\n",
    "# Define the fitness function\n",
    "def evaluate_model(model, train_data, val_data):\n",
    "    train_images, train_labels = train_data\n",
    "    val_images, val_labels = val_data\n",
    "    history = model.fit(train_images, train_labels, batch_size=32, epochs=10, validation_data=(val_images, val_labels))\n",
    "    return history.history['val_accuracy'][-1],\n",
    "\n",
    "# Define the genetic algorithm parameters\n",
    "POP_SIZE = 10\n",
    "GEN_SIZE = 10\n",
    "CXPB = 0.5\n",
    "MUTPB = 0.2\n",
    "\n",
    "# Create a fitness function with the appropriate number of input arguments\n",
    "creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "\n",
    "# Define the toolbox\n",
    "toolbox = base.Toolbox()\n",
    "\n",
    "# Define the initialization function for the individuals\n",
    "def init_individual():\n",
    "    return [np.random.randint(16, 64), np.random.uniform(0.0, 0.5), np.random.uniform(0.0, 0.5), np.random.uniform(0.0, 0.5)]\n",
    "\n",
    "# Define the evaluation function for the individuals\n",
    "def evaluate_individual(individual, train_data, val_data):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(individual[0], (3,3), activation='relu', padding='same', input_shape=(120, 120, 3)))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(individual[0]*2, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Conv2D(individual[0]*4, (3,3), activation='relu', padding='same'))\n",
    "    model.add(MaxPooling2D((2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(individual[1]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(individual[2]))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(individual[3]))\n",
    "    model.add(Dense(120*120*1, activation='softmax'))\n",
    "    model.add(Reshape((120, 120, 1)))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return evaluate_model(model, train_data, val_data)\n",
    "\n",
    "# Register the functions with the toolbox\n",
    "toolbox.register(\"individual\", tools.initIterate, creator.Individual, init_individual)\n",
    "toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.1)\n",
    "toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "toolbox.register(\"evaluate\", evaluate_individual, train_data=(train_images, train_labels), val_data=(val_images, val_labels))\n",
    "\n",
    "# Create the initial population\n",
    "pop = toolbox.population(n=POP_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 93s 2s/step - loss: 2956.3269 - accuracy: 0.0000e+00 - val_loss: 1977.9613 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 82s 3s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9601 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 76s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 85s 3s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9596 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 75s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 76s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 76s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 89s 3s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 77s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 98s 3s/step - loss: 2968.4089 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9596 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 68s 2s/step - loss: 2952.4807 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9594 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9590 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.5208 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 77s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 70s 2s/step - loss: 2941.3730 - accuracy: 0.0000e+00 - val_loss: 1977.9594 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9590 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 72s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 67s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 67s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 76s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 69s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 67s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 38s 1s/step - loss: 2949.8560 - accuracy: 0.0000e+00 - val_loss: 1977.9601 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9596 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 37s 1s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 32s 1s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 33s 1s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 31s 965ms/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 30s 949ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 31s 961ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 58s 2s/step - loss: 2921.3318 - accuracy: 0.0000e+00 - val_loss: 1977.9630 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 52s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 60s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 55s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 51s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 52s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 50s 2s/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 52s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 73s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 50s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 71s 2s/step - loss: 2979.0591 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 89s 3s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 63s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 71s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 77s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 68s 2s/step - loss: 2954.7117 - accuracy: 0.0000e+00 - val_loss: 1977.9601 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 79s 3s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 72s 2s/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 59s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 64s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 94s 3s/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 62s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 65s 2s/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9579 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 33s 902ms/step - loss: 2976.2986 - accuracy: 0.0000e+00 - val_loss: 1977.9628 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 28s 888ms/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9596 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 28s 872ms/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9594 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 28s 891ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 28s 871ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9590 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 28s 884ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 28s 886ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9585 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 28s 887ms/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 28s 885ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 28s 875ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9581 - val_accuracy: 0.0669\n",
      "Epoch 1/10\n",
      "32/32 [==============================] - 37s 940ms/step - loss: 2975.2888 - accuracy: 0.0000e+00 - val_loss: 1977.9604 - val_accuracy: 0.0669\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 29s 915ms/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9598 - val_accuracy: 0.0669\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 29s 917ms/step - loss: 2872.5000 - accuracy: 0.0000e+00 - val_loss: 1977.9596 - val_accuracy: 0.0669\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 29s 902ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9592 - val_accuracy: 0.0669\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 29s 912ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9587 - val_accuracy: 0.0669\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 29s 913ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 29s 913ms/step - loss: 2872.4998 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 29s 918ms/step - loss: 2872.4995 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 29s 907ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 29s 905ms/step - loss: 2872.4993 - accuracy: 0.0000e+00 - val_loss: 1977.9584 - val_accuracy: 0.0669\n",
      "Best individual: 0.06688474863767624\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Individual' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBest individual: \u001b[39m\u001b[39m{\u001b[39;00mbest_ind\u001b[39m.\u001b[39mfitness\u001b[39m.\u001b[39mvalues[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[39m# Save the best individual of this generation\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m best_ind\u001b[39m.\u001b[39;49msave(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbest_individual_\u001b[39m\u001b[39m{\u001b[39;00mg\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.pkl\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Individual' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Run the genetic algorithm\n",
    "# Define the number of generations\n",
    "NGEN = 10\n",
    "for g in range(NGEN):\n",
    "    print(f\"Generation {g+1}\")\n",
    "    # Select the next generation\n",
    "    offspring = toolbox.select(pop, len(pop))\n",
    "    \n",
    "    # Apply crossover and mutation to create the offspring\n",
    "    offspring = list(map(toolbox.clone, offspring))\n",
    "    for ind1, ind2 in zip(offspring[::2], offspring[1::2]):\n",
    "        if np.random.rand() < CXPB:\n",
    "            toolbox.mate(ind1, ind2)\n",
    "            del ind1.fitness.values\n",
    "            del ind2.fitness.values\n",
    "    \n",
    "    for mutant in offspring:\n",
    "        if np.random.rand() < MUTPB:\n",
    "            toolbox.mutate(mutant)\n",
    "            del mutant.fitness.values\n",
    "    \n",
    "    # Evaluate the fitness of the offspring\n",
    "    invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "    fitnesses = map(toolbox.evaluate, invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitnesses):\n",
    "        ind.fitness.values = fit\n",
    "        \n",
    "    # Replace the population with the offspring\n",
    "    pop[:] = offspring\n",
    "    \n",
    "    # Print the best individual of this generation\n",
    "    best_ind = tools.selBest(pop, 1)[0]\n",
    "    print(f\"Best individual: {best_ind.fitness.values[0]}\")\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
